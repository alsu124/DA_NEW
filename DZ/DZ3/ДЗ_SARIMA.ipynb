{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание: SARIMA (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оформление дз**: \n",
    "\n",
    "- Task short name: ``DZ SARIMA``.\n",
    "- Выполненное дз сохраните в своей папке github\n",
    "\n",
    "**Вопросы**:\n",
    "- Свои вопросы присылайте в Telegram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import pandas as pd\n",
    "import math\n",
    "import pandas.tseries.offsets as ofs\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa import stattools\n",
    "\n",
    "import warnings as w\n",
    "import plotly.plotly as py\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные. Они содержат интервал с пропущенными значениями. Выделим отдельно временной ряд `ts_no_outs` без большого пропуска. По умолчанию будем работать с ним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_csv('dataset1_with_outliers_data.csv')\n",
    "ts.index = pd.to_datetime(ts['ds'])\n",
    "ts = ts.drop(['ds'], axis=1)\n",
    "ts.sort_index(inplace=True)\n",
    "\n",
    "ts_full = ts\n",
    "ts_no_outs = ts[datetime(2012, 1,1):]\n",
    "del ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_full.plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_no_outs.plot(figsize=(15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1. Проверка ряда на стационарность (20%)\n",
    "\n",
    "Проверьте ряд на стационарность (например, с помощью критерия [Дики-Фуллера](https://ru.wikipedia.org/wiki/Тест_Дики_—_Фуллера)). Попробуйте привести его к стационарному виду (с помощью преобразования Бокса-Кокса, дифференцирования etc.)\n",
    "\n",
    "После получения стационарного ряда напишите функцию прямой `transform` и обратной `inv_transform` трансформации временного ряда (т.е. исходный ряд -> стационарный ряд и стационарный ряд -> исходный ряд)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(ts):\n",
    "    ### Your code here\n",
    "    \n",
    "\n",
    "def inv_transform(ts):\n",
    "    ### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2. Обнаружение выбросов (10%).\n",
    "С помощью экспоненциального сглаживания найдите выбросы в данных (и попробуйте их сгладить). Для этого подберите оптимальные значения параметров `alpha`, `beta` и `std_window`. Функция для детекции аномалий и сглаживания приведена ниже. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing_anomaly_filter(series, alpha, beta=2.5, std_window=10):\n",
    "    \"\"\"\n",
    "    Anomaly filter based on simple exponential smoothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pandas.Series\n",
    "        Time series to smooth.\n",
    "    alpha : float in range [0., 1.]\n",
    "        Smoothing parameter. The smaller is `alpha`, the smoother are result series.\n",
    "    beta: float\n",
    "        Multiplier for rolling standard deviation. If the deviation from smoothed time series in some point is bigger\n",
    "        than `beta`*rolling_std, that point is marked as anomaly.\n",
    "    std_window : int\n",
    "        Rolling std window width.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    _ : pandas.Series\n",
    "        Smoothed time series.\n",
    "    _ : pandas.Series\n",
    "        Series containing anomalies (both time and value).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    result = [series[0]] # first value is same as series\n",
    "    sx = series.rolling(std_window).std()\n",
    "    anomalies_index = []\n",
    "    anomalies_values = []\n",
    "#     print(len(series), len(sx))\n",
    "    for n in range(1, len(series)):\n",
    "        if n > std_window:\n",
    "            if abs(series[n] - result[n-1]) > sx[n]*beta:\n",
    "                result.append(result[n-1])\n",
    "                anomalies_index.append(series.index[n])\n",
    "                anomalies_values.append(series[n])\n",
    "                continue\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    return pd.Series(index=series.index, data=result), pd.Series(index=anomalies_index, data=anomalies_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 3. Построение SARIMA модели (60%)\n",
    "Так как данная часть не разбиралась на лекции, крайне рекомнедуем к прочтению (приведенным в статье кодом также можно пользоваться) часть по SARIMA [занятия №9 курса от ODS](https://habr.com/company/ods/blog/327242/) (это тот же материал, на который ссылается ноутбук из части 0, но в виде статьи). Также может быть полезным прочитать [раз](http://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/) и [два](https://github.com/Yorko/mlcourse_open/blob/master/jupyter_russian/topic09_time_series/Time_Series_Riabenko.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARIMA available in sm.tsa.statespace.SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите оптимальные коэффициенты `p`, `d`, `q` и `P`, `D`, `Q` для SARIMA модели и постройте свой прогноз. Подбирать оптимальные значения стоит с помощью кросс-валидации (отсылка к семинару ;) ). Обучение будем проводить только на `ts_train`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пойстройте ACF и PACF, оцените по ним параметры `p`, `q`, `P`, `Q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переберите несколько возможных комбинаций параметров. Оцените качество и выберите лучший набор параметров. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогноз будем делать на 2 недели вперед. Оцените качество прогноза с помощью MSE, MAE и $r^2$-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 4. Сравнение с линейной авторегрессией. (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сравним результаты SARIMA с простой линейной авторегрессией. Для построения авторегрессионной матрицы воспользуемся функцией из курса ODS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(data, lag_start=5, lag_end=20, test_size=0.15):\n",
    "\n",
    "    data = pd.DataFrame(data.copy())\n",
    "    data.columns = [\"y\"]\n",
    "\n",
    "    # считаем индекс в датафрейме, после которого начинается тестовыый отрезок\n",
    "    test_index = int(len(data)*(1-test_size))\n",
    "\n",
    "    # добавляем лаги исходного ряда в качестве признаков\n",
    "    for i in range(lag_start, lag_end):\n",
    "        data[\"lag_{}\".format(i)] = data.y.shift(i)\n",
    "\n",
    "    data.index = data.index.to_datetime()\n",
    "    data[\"hour\"] = data.index.hour\n",
    "    data[\"weekday\"] = data.index.weekday\n",
    "    data['is_weekend'] = data.weekday.isin([5,6])*1\n",
    "\n",
    "    data = data.dropna()\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # разбиваем весь датасет на тренировочную и тестовую выборку\n",
    "    X_train = data.loc[:test_index].drop([\"y\"], axis=1)\n",
    "    y_train = data.loc[:test_index][\"y\"]\n",
    "    X_test = data.loc[test_index:].drop([\"y\"], axis=1)\n",
    "    y_test = data.loc[test_index:][\"y\"]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем начинать с 14 лага (т.е. модель может построить прогноз на 2 недели вперед на исторических данных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepareData(ts_train, test_size=0.3, lag_start=14, lag_end=49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем матрицу `X_train` (это часть авторегрессионной матрицы) с учетом дополнительных данных о выходных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.pcolor(X_train)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "prediction = lr.predict(X_test)\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(prediction, \"r\", label=\"prediction\")\n",
    "plt.plot(y_test.values, label=\"actual\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Linear regression\\n Mean absolute error {} \".format(mean_absolute_error(prediction, y_test)))\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните полученное качество предсказания с также с помощью MSE и $r^2$-score. Получился ли результат лучше, чем в случае с SARIMA? Как думаете, почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
